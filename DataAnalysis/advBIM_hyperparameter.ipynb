{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_num = 10\n",
    "font = 14\n",
    "\n",
    "def readfile(pred_data):\n",
    "    data = pd.read_csv(pred_data).T.to_numpy()\n",
    "    \n",
    "    f1 = np.array([f1_score(data[0], data[i],average=None) for i in range(1,round_num+1)]).T\n",
    "    precision = np.array([precision_score(data[0], data[i],average=None) for i in range(1,round_num+1)]).T\n",
    "    recall = np.array([recall_score(data[0], data[i],average=None) for i in range(1,round_num+1)]).T\n",
    "    accuracy = np.array([accuracy_score(data[0], data[i]) for i in range(1,round_num+1)])\n",
    "    \n",
    "    f1 = np.array([f1_score(data[0], data[i],average=None) for i in range(1,round_num+1)]).T\n",
    "    precision = np.array([precision_score(data[0], data[i],average=None) for i in range(1,round_num+1)]).T\n",
    "    recall = np.array([recall_score(data[0], data[i],average=None) for i in range(1,round_num+1)]).T\n",
    "    accuracy = np.array([accuracy_score(data[0], data[i]) for i in range(1,round_num+1)])\n",
    "    \n",
    "    return f1, precision, recall, accuracy\n",
    "\n",
    "\n",
    "def plotfile(f, f1, precision, recall, accuracy):\n",
    "    x = [x*10 for x in range(round_num)]\n",
    "    # fig, ax = plt.subplots(1,3, figsize=(15,4.5))\n",
    "    # [ax[0].plot(x, f1[i], label=f'label{i}') for i in range(3)]\n",
    "    # [ax[1].plot(x, precision[i], label=f'label{i}') for i in range(3)]\n",
    "    # [ax[2].plot(x, recall[i], label=f'label{i}') for i in range(3)]\n",
    "    # ax[0].set_ylabel('f1', size=font)\n",
    "    # ax[1].set_ylabel('precision', size=font)\n",
    "    # ax[2].set_ylabel('recall', size=font)\n",
    "    # [ax[i].set_xlabel('Number of Finetunning Samples', size=font) for i in range(3)]\n",
    "    # plt.legend(bbox_to_anchor=(1.3, 0.6))\n",
    "    # fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    # plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(1,4, figsize=(20,5))\n",
    "    ax[0].plot(x, accuracy, label='accuracy')\n",
    "    ax[0].set_ylabel('accuracy', size=font)\n",
    "    ax[1].plot(x, np.mean(f1, axis=0), label='f1')\n",
    "    ax[1].set_ylabel('f1', size=font)\n",
    "    ax[2].plot(x, np.mean(precision, axis=0), label='precision')\n",
    "    ax[2].set_ylabel('precision', size=font)\n",
    "    ax[3].plot(x, np.mean(recall, axis=0), label='recall')\n",
    "    ax[3].set_ylabel('recall', size=font)\n",
    "    # [ax[i].set_xlabel(':Number of Finetunning Samples', size=font) for i in range(4)]\n",
    "    ax[1].set_xlabel(f'{f}:Number of Finetunning Samples', size=font)\n",
    "    # plt.legend(bbox_to_anchor=(1.0, 0.6))\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir('/egr/research-aidd/menghan1/AnchorDrug/ActiveLearning_one_cellline/logfile/')\n",
    "file_list_A549 = [f[:-4] for f in file_list if 'A549_AdversarialBIM' in f]\n",
    "file_list_MCF7 = [f[:-4]  for f in file_list if 'MCF7_AdversarialBIM' in f]\n",
    "file_list_PC3 = [f[:-4]  for f in file_list if 'PC3_AdversarialBIM' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/egr/research-aidd/menghan1/AnchorDrug/ActiveLearning_one_cellline/preds'\n",
    "\n",
    "f1 = np.zeros((3,round_num))\n",
    "precision = np.zeros((3,round_num))\n",
    "recall = np.zeros((3,round_num))\n",
    "accuracy = np.zeros(round_num)\n",
    "xa549 = []\n",
    "ya549 = []\n",
    "for f in np.sort(file_list_A549):\n",
    "    xa549.append(float(f.split('-')[1]))\n",
    "    for n in [0,1,2,3,4]:\n",
    "        pred_data = f'{root_dir}/{f}_{n}.csv'\n",
    "        a,b,c,d = readfile(pred_data)\n",
    "        f1 += a\n",
    "        precision += b\n",
    "        recall += c\n",
    "        accuracy += d\n",
    "    f1 /= 5\n",
    "    precision /= 5\n",
    "    recall /= 5\n",
    "    accuracy /= 5\n",
    "    ya549.append(np.mean(f1, axis=0)[[-1]])\n",
    "\n",
    "f1 = np.zeros((3,round_num))\n",
    "precision = np.zeros((3,round_num))\n",
    "recall = np.zeros((3,round_num))\n",
    "accuracy = np.zeros(round_num)\n",
    "xpc3 = []\n",
    "ypc3 = []\n",
    "for f in np.sort(file_list_PC3):\n",
    "#     xpc3.append(float(f.split('-')[1]))\n",
    "#     for n in [0,1,2,3,4]:\n",
    "#         pred_data = f'{root_dir}/{f}_{n}.csv'\n",
    "#         a,b,c,d = readfile(pred_data)\n",
    "#         f1 += a\n",
    "#         precision += b\n",
    "#         recall += c\n",
    "#         accuracy += d\n",
    "#     f1 /= 5\n",
    "#     precision /= 5\n",
    "#     recall /= 5\n",
    "#     accuracy /= 5\n",
    "#     ypc3.append(np.mean(f1, axis=0)[[-1]])\n",
    "\n",
    "f1 = np.zeros((3,round_num))\n",
    "precision = np.zeros((3,round_num))\n",
    "recall = np.zeros((3,round_num))\n",
    "accuracy = np.zeros(round_num)\n",
    "xmcf7 = []\n",
    "ymcf7 = []\n",
    "for f in np.sort(file_list_MCF7):\n",
    "    xmcf7.append(float(f.split('-')[1]))\n",
    "    for n in [0,1,2,3,4]:\n",
    "        pred_data = f'{root_dir}/{f}_{n}.csv'\n",
    "        a,b,c,d = readfile(pred_data)\n",
    "        f1 += a\n",
    "        precision += b\n",
    "        recall += c\n",
    "        accuracy += d\n",
    "    f1 /= 5\n",
    "    precision /= 5\n",
    "    recall /= 5\n",
    "    accuracy /= 5\n",
    "    ymcf7.append(np.mean(f1, axis=0)[[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(4,4))\n",
    "ax.plot(xa549, ya549, 'o-', label='A549')\n",
    "ax.plot(xmcf7, ymcf7, 'o-', label='MCF7')\n",
    "ax.plot(xpc3, ypc3, 'o-', label='PC3')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xlabel('Ratio')\n",
    "# plt.title('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/egr/research-aidd/menghan1/AnchorDrug/ActiveLearning_one_cellline/preds'\n",
    "f1 = np.zeros((3,round_num))\n",
    "precision = np.zeros((3,round_num))\n",
    "recall = np.zeros((3,round_num))\n",
    "accuracy = np.zeros(round_num)\n",
    "x = []\n",
    "y = []\n",
    "for f in np.sort(file_list_MCF7):\n",
    "    x.append(float(f.split('-')[1]))\n",
    "    for n in [0,1,2,3,4]:\n",
    "        pred_data = f'{root_dir}/{f}_{n}.csv'\n",
    "        a,b,c,d = readfile(pred_data)\n",
    "        f1 += a\n",
    "        precision += b\n",
    "        recall += c\n",
    "        accuracy += d\n",
    "    f1 /= 5\n",
    "    precision /= 5\n",
    "    recall /= 5\n",
    "    accuracy /= 5\n",
    "    plotfile(f, f1, precision, recall, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# distance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
